from pathlib import Path
from typing import Union
import numpy as np
from scipy.stats import rankdata
import pandas as pd
import polars as pl
import math
from typing import Tuple, List, Optional, Dict
from itertools import repeat
import altrios as alt
from altrios import utilities
pl.enable_string_cache(True)

class TrainPlannerConfig:
    def __init__(self, 
                 manifest_empty_return_ratio: float = 0.6,
                 target_train_length: int = 100,
                 cars_per_locomotive: int = 70,
                 ton_per_car: Dict = {
                    "Unit": 80,
                    "Unit_Empty": 30,
                    "Intermodal": 70,
                    "Intermodal_Empty": 15,
                    "Manifest": 100,
                    "Manifest_Empty": 30,
                    },
                 hp_required_per_ton: Dict = {
                     "Default": {
                        "Unit": 1+2.0,
                        "Manifest": 1.5+2.0,
                        "Intermodal": 2+2.0,
                        "Unit_Empty": 1+2.0,
                        "Manifest_Empty": 1.5+2.0,
                        "Intermodal_Empty": 2+2.0,
                        }                         
                     }, 
                 dispatch_scaling_dict: Dict = {
                     "time_mult_factor": 1.4,
                     "hours_add": 2,
                     "energy_mult_factor": 1.25
                     },
                 loco_info = pd.DataFrame({
                    "Diesel_Large": {
                        "Capacity_Cars": 20,
                        "Min_Servicing_Time[hr]": 3.0,
                        "Rust_Loco": alt.Locomotive.default(),
                    },
                    "BEL": {
                        "Capacity_Cars": 20,
                        "Min_Servicing_Time[hr]": 3.0,
                        "Rust_Loco": alt.Locomotive.default_battery_electic_loco(),
                    }
                }).transpose().reset_index(names='Type')
                ):
        """
        Constructor for train planner configuration objects
        Arguments:
        ----------
        manifest_empty_return_ratio: Desired railcar reuse ratio to calculate the empty manifest car demand, (E_ij+E_ji)/(L_ij+L_ji)
        target_train_length:
        cars_per_locomotive: Heuristic scaling factor used to size number of locomotives needed based on demand.
        ton_per_car:
        hp_required_per_ton:
        dispatch_scaling_dict:
        loco_info:
        """
        self.manifest_empty_return_ratio = manifest_empty_return_ratio
        self.target_train_length = target_train_length
        self.cars_per_locomotive = cars_per_locomotive
        self.ton_per_car = ton_per_car
        self.hp_required_per_ton = hp_required_per_ton
        self.dispatch_scaling_dict = dispatch_scaling_dict
        self.loco_info = loco_info

DEFAULT_DIESEL_TANK_CAPACITY = (5000 / utilities.GALLONS_PER_LITER / utilities.LITER_PER_M3) * \
    utilities.RHO_DIESEL_KG_PER_M3 * utilities.LHV_DIESEL_KJ_PER_KG * 1e3
DEFAULT_REFUEL_RATE = (300 * 60 / utilities.GALLONS_PER_LITER / utilities.LITER_PER_M3) * \
    utilities.RHO_DIESEL_KG_PER_M3 * utilities.LHV_DIESEL_KJ_PER_KG * 1e3 # 300 gallons per minute -> joules per hour
DEFAULT_BEL_CHARGE_RATE = (0.75 / utilities.MWH_PER_MJ) * 1e6 # 750 kW -> joules per hour

def demand_loader(
    user_input_file: Union[Path, str]
) -> Tuple[pd.DataFrame, pd.Series, int]:
    """
    Load the user input csv file into a dataframe for later processing
    Arguments:
    ----------
    user_input_file: path to the input csv file that user import to the module
    Example Input:
        Origin	Destination	Train_Type	Number_of_Cars	Number_of_Containers
        Barstow	Stockton	Unit	    2394	        0
        Barstow	Stockton	Manifest	2588	        0
        Barstow	Stockton	Intermodal	2221	        2221
    Outputs:
    ----------
    df_annual_demand: dataframe with all pair information including:
    origin, destination, train type, number of cars
    node_list: List of origin or destination demand nodes
    """
    df_annual_demand = pd.read_csv(user_input_file)
    node_list = pd.concat(
        (df_annual_demand["Origin"],
         df_annual_demand["Destination"])
    ).unique()

    return df_annual_demand, node_list


def additional_demand(
    df_annual_demand: pd.DataFrame,
    config: TrainPlannerConfig
) -> pd.DataFrame:
    """
    Create a dataframe for additional demand needed for empty cars of the return trains
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    config: Object storing train planner configuration paramaters
    Outputs:
    ----------
    df_additional_demand: The demand generated by the need
    of returning the empty cars to their original nodes
    """
    df_additional_demand = pd.DataFrame(
        np.zeros(shape=np.shape(df_annual_demand)),
        columns=df_annual_demand.columns)

    df_additional_demand["Origin"] = df_annual_demand["Destination"]
    df_additional_demand["Destination"] = df_annual_demand["Origin"]
    df_additional_demand["Train_Type"] = df_annual_demand["Train_Type"]

    for i in range(len(df_annual_demand)):
        df_additional_demand.loc[i,
                                 "Number_of_Containers"] = df_annual_demand.loc[i, "Number_of_Containers"]
        if df_additional_demand.loc[i, "Train_Type"] == "Manifest":
            df_additional_demand.loc[i, "Number_of_Cars"] = np.floor(
                df_annual_demand.loc[i, "Number_of_Cars"] * config.manifest_empty_return_ratio)
        else:
            df_additional_demand.loc[i,
                                     "Number_of_Cars"] = df_annual_demand.loc[i, "Number_of_Cars"]

    return df_additional_demand

def origin_manifest_demand(
    df_annual_demand: pd.DataFrame,
    node_list: List[str],
    config: TrainPlannerConfig
) -> pd.DataFrame:
    """
    Create a dataframe for summarized view of all origins' manifest demand
    in number of cars and received cars, both with loaded and empty counts
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    node_list: A list containing all the names of nodes in the system    
    config: Object storing train planner configuration paramaters

    Outputs:
    ----------
    df_origin_manifest_demand: The dataframe that summarized all the manifest demand
    originated from each node by number of loaded and empty cars
    with additional columns for checking the unbalance quantity and serve as check columns
    for the manifest empty car rebalancing function
    """
    df_origin_manifest_demand = pd.DataFrame(
        np.zeros(shape=(len(node_list), 8)),
        columns=[
            "Origin",
            "Manifest",
            "Manifest_Empty",
            "Manifest_Dispatched",
            "Manifest_Received",
            "Manifest_Dispatched_Check",
            "Manifest_Received_Check",
            "Manifest_Empty_Updated",
        ]
    )

    df_origin_manifest_demand["Origin"] = node_list

    for i in range(len(df_annual_demand)):
        for j in range(len(node_list)):
            if (df_annual_demand.loc[i, "Origin"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"]
            if (df_annual_demand.loc[i, "Destination"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Empty"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"] * config.manifest_empty_return_ratio
            if (df_annual_demand.loc[i, "Destination"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Received"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"]
            if (df_annual_demand.loc[i, "Origin"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Received"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"] * config.manifest_empty_return_ratio

    df_origin_manifest_demand["Manifest_Dispatched"] = (
        df_origin_manifest_demand["Manifest"] +
        df_origin_manifest_demand["Manifest_Empty"]
    )

    for i in range(len(df_origin_manifest_demand)):
        df_origin_manifest_demand.loc[i, "Manifest_Received_Check"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Received"]
        df_origin_manifest_demand.loc[i, "Manifest_Dispatched_Check"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Dispatched"]
        df_origin_manifest_demand.loc[i, "Manifest_Empty_Updated"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Empty"]

    return df_origin_manifest_demand


def train_balancer(
    df_origin_manifest_demand: pd.DataFrame
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Update the manifest demand, especially the empty car demand to maintain equilibrium of number of
    cars dispatched and received at each node for manifest
    Arguments:
    ----------
    df_origin_manifest_demand: The dataframe that summarized all the manifest demand
    originated from each node by number of loaded and empty cars
    with additional columns for checking the unbalance quantity and serve as check columns
    Outputs:
    ----------
    df_origin_manifest_demand: Updated df_origin_manifest_demand with additional
    manifest empty car demand added to each node
    df_balance_storage: Documented additional manifest demand pairs and corresponding quantity for
    rebalancing process
    """
    # Creating a copy of the origin manifest demand,
    # which is a dataframe of the number of manifest cars dispatched and received for each node,
    # with two checking columns for modifications
    # df_origin_manifest_demand_copy = df_origin_manifest_demand.copy()
    # Calculate the number of iterations needed
    df_balance_storage = np.zeros(shape=(0, 3))
    df_balance_storage = pd.DataFrame(df_balance_storage)
    df_balance_storage = df_balance_storage.rename(
        columns={0: "Origin", 1: "Destination", 2: "Extra_Empty", })

    step = 0
    max_iter = len(df_origin_manifest_demand) * \
        (len(df_origin_manifest_demand)-1) / 2
    while (~np.isclose(df_origin_manifest_demand["Manifest_Received_Check"],
                       df_origin_manifest_demand["Manifest_Dispatched_Check"])).any() and (step <= max_iter):
        for row_def in range(len(df_origin_manifest_demand)):
            # Find the first node that is in deficit of cars because of the empty return
            if df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] \
                    < df_origin_manifest_demand.loc[row_def, "Manifest_Dispatched_Check"]:
                for row_sur in range(len(df_origin_manifest_demand)):
                    # Find the first node that is in surplus of cars
                    if df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] \
                            > df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"]:
                        df_balance_storage.loc[len(df_balance_storage.index)] = [df_origin_manifest_demand.loc[row_sur, "Origin"],
                                                                                 df_origin_manifest_demand.loc[
                                                                                     row_def, "Origin"],
                                                                                 (df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] -
                                                                                  df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"])
                                                                                 ]
                        df_origin_manifest_demand.loc[row_sur, "Manifest_Empty_Updated"] \
                            = df_origin_manifest_demand.loc[row_sur, "Manifest_Empty_Updated"] + \
                            df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] - \
                            df_origin_manifest_demand.loc[row_sur,
                                                          "Manifest_Dispatched_Check"]
                        df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] \
                            = df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] + \
                            df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] - \
                            df_origin_manifest_demand.loc[row_sur,
                                                          "Manifest_Dispatched_Check"]
                        df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"] \
                            = df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"]

                        step += 1
                        break
    if (~np.isclose(df_origin_manifest_demand["Manifest_Received_Check"],
                    df_origin_manifest_demand["Manifest_Dispatched_Check"])).any():
        raise Exception("While loop didn't converge")
    return df_origin_manifest_demand, df_balance_storage


def demand_pair_generator(
    df_annual_demand: pd.DataFrame,
    df_additional_demand: pd.DataFrame,
    df_balance_storage: pd.DataFrame,
    node_list: List[str]
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the final demand
    for each demand pair for each train type in number of cars
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    df_additional_demand: The demand generated by the need
    of returning the empty cars to their original nodes
    df_balance_storage: Documented additional manifest demand pairs and corresponding quantity for
    rebalancing process
    node_list: A list containing all the names of nodes in the system
    Outputs:
    ----------
    df_demand_pair: Tabulated demand for each demand pair for each train type
    """
    # Dispatch logic curretly set to be dispatching in 100 cars when applicable
    df_demand_pair = pd.DataFrame(
        np.zeros(shape=(len(node_list)*(len(node_list)-1), 9)),
        columns=[
            'Origin',
            'Destination',
            'Intermodal',
            'Intermodal_Empty',
            'Unit',
            'Unit_Empty',
            'Manifest',
            'Manifest_Empty',
            'Total'
        ]
    )

    for i in range(len(node_list)):
        iter = 0
        for j in range(len(node_list)):
            if i != j:
                df_demand_pair.loc[
                    i*(len(node_list)-1)+iter, "Origin"
                ] = node_list[i]
                df_demand_pair.loc[
                    i*(len(node_list)-1)+iter, "Destination"
                ] = node_list[j]
                iter += 1
    type = {"Intermodal": 1, "Unit": 2, "Manifest": 3}
    nodes = {row["Origin"] + row["Destination"]             : i for (i, row) in df_demand_pair.iterrows()}

    for (i, row) in df_annual_demand.iterrows():
        df_demand_pair.iloc[
            nodes[row["Origin"] + row["Destination"]], 2 *
            type[row["Train_Type"]]
        ] = row["Number_of_Cars"]

    for (i, row) in df_additional_demand.iterrows():
        df_demand_pair.iloc[
            nodes[row["Origin"] + row["Destination"]], 2 *
            type[row["Train_Type"]] + 1
        ] += row["Number_of_Cars"]

    for (i, row) in df_balance_storage.iterrows():
        df_demand_pair.loc[
            nodes[
                row["Origin"] + row["Destination"]
            ], "Manifest_Empty"
        ] += row["Extra_Empty"]

    df_demand_pair["Total"] = df_demand_pair.iloc[:, 2:-1].sum(axis=1)

    return df_demand_pair


def demand_train_generator(
    df_demand_pair: pd.DataFrame,
    min_length: int = 60,
    desired_length: int = 100
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the final demand
    for each demand pair for each train type in number of trains
    Arguments:
    ----------
    df_demand_pair: Tabulated demand for each demand pair for each train type in number of cars
    min_length: the minimum length in number of cars to form a train
    desired_length: the standard train length in number of cars
    Outputs:
    ----------
    df_demand_train: Tabulated demand for each demand pair for each train type in number of trains
    """
    df_demand_train = df_demand_pair.copy()

    for i in range(len(df_demand_train)):
        temp = df_demand_pair.loc[i, "Manifest"] + \
            df_demand_pair.loc[i, "Manifest_Empty"]
        if temp - np.floor(temp/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Manifest"] = np.floor(
                temp/desired_length) + 1
        else:
            df_demand_train.loc[i, "Manifest"] = np.floor(temp/desired_length)
        df_demand_train.loc[i,
                            "Manifest_Empty"] = df_demand_train.loc[i, "Manifest"]

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Intermodal"] != 0:
            if df_demand_pair.loc[i, "Intermodal"] - np.floor(df_demand_pair.loc[i, "Intermodal"]/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal"]/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal"]/desired_length)
        if df_demand_pair.loc[i, "Intermodal_Empty"] != 0:
            if df_demand_pair.loc[i, "Intermodal_Empty"] - np.floor(df_demand_pair.iloc[i, 3]/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal_Empty"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal_Empty"]/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal_Empty"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal_Empty"]/desired_length)
        if df_demand_pair.loc[i, "Intermodal"] != 0 and df_demand_pair.loc[i, "Intermodal_Empty"] != 0:
            temp = df_demand_pair.loc[i, "Intermodal"] + \
                df_demand_pair.loc[i, "Intermodal_Empty"]
            if temp - np.floor(temp/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    temp/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    temp/desired_length)
            df_demand_train.loc[i, "Intermodal_Empty"] = 0.0

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Unit"] - np.floor(df_demand_pair.loc[i, "Unit"]/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Unit"] = np.floor(
                df_demand_pair.loc[i, "Unit"]/desired_length) + 1
        else:
            df_demand_train.loc[i, "Unit"] = np.floor(
                df_demand_pair.loc[i, "Unit"]/desired_length)

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Unit_Empty"] - np.floor(df_demand_pair.loc[i, "Unit_Empty"]/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Unit_Empty"] = np.floor(
                df_demand_pair.loc[i, "Unit_Empty"]/desired_length) + 1
        else:
            df_demand_train.loc[i, "Unit_Empty"] = np.floor(
                df_demand_pair.loc[i, "Unit_Empty"]/desired_length)
    for i in range(len(df_demand_train)):
        df_demand_train.loc[i, "Total"] = 0
        for j in range(5):
            df_demand_train.loc[i, "Total"] += df_demand_train.iloc[i, j+2]

    return df_demand_train


def timestep_calculator(
    config: TrainPlannerConfig,
    df_demand_train: pd.DataFrame,
    time_steps: int = 21*24*10
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the expected dispatching interval
    and actual dispatching timesteps after rounding
    Arguments:
    ----------
    config: Object storing train planner configuration paramaters
    df_demand_train: Tabulated demand for each demand pair for each train type in number of trains
    time_steps: Number of iterations, a product of time interval (number of iterations per hour)
    and time period (in hours)
    Outputs:
    ----------
    df_timesteps: Tabulated dispatching time for each demand pair for each train type
    in hours
    """
    df_rounded_intervals = pd.melt(df_demand_train, 
                                   id_vars=['Origin', 'Destination'], 
                                   value_vars=[k for k in config.ton_per_car.keys()]
                                   )
    df_rounded_intervals.loc[:, 'interval'] = round(
        time_steps / df_rounded_intervals.loc[:, 'value'])
    df_rounded_intervals = df_rounded_intervals[(
        df_rounded_intervals['value'] > 0) & (df_rounded_intervals['interval'] > 0)]
    column_names = ['Timestep', 'Origin', 'Destination', 'Train Type']
    df_timesteps = pd.DataFrame(columns=column_names)
    for j, row in df_rounded_intervals.iterrows():
        timesteps = np.arange(1, row.loc['value']+1)*row.loc['interval']
        new_row_count = len(timesteps)
        new_rows = pd.DataFrame(list(zip(
            timesteps,
            repeat(row.loc['Origin'], new_row_count),
            repeat(row.loc['Destination'], new_row_count),
            repeat(row.loc['variable'], new_row_count))),
            columns=column_names)

        df_timesteps = pd.concat(
            (
                df_timesteps,
                new_rows)
        ).reset_index(drop=True)

    df_timesteps.sort_values(
        by=['Timestep', 'Origin', 'Destination', 'Train Type'],
        inplace=True)
    df_timesteps.reset_index(drop=True, inplace=True)

    return df_timesteps

def build_locopool(
    config: TrainPlannerConfig,
    demand_file: str = alt.resources_root() / "Default Demand.csv",
    method: str = "tile",
    shares: List[float] = [],
) -> pl.DataFrame:
    """
    Generate default locomotive pool
    Arguments:
    ----------
    demand_file: Path to a file with origin-destination demand
    method: Method to determine each locomotive's type ("tile" or "shares_twoway" currently implemented)
    shares: List of shares for each locomotive type in loco_info (implemented for two-way shares only)
    Outputs:
    ----------
    loco_pool: Locomotive pool containing all locomotives' information that are within the system
    """
    df_annual_demand, node_list = demand_loader(demand_file)
    config.loco_info = update_loco_info(config.loco_info)
    loco_types = list(config.loco_info.loc[:,'Type'])
    num_nodes = len(node_list)
    num_ods = len(df_annual_demand)
    cars_per_od = np.mean(df_annual_demand['Number_of_Cars'])
    num_destinations_per_node = num_ods / num_nodes
    initial_size = math.ceil((cars_per_od / config.cars_per_locomotive) *
                             num_destinations_per_node)  # number of locomotives per node

    rows = initial_size * num_nodes  # number of locomotives in total
    sorted_nodes = np.sort(np.tile(node_list, initial_size)).tolist()
    engine_numbers = rankdata(sorted_nodes, method="dense") * 1000 + \
        np.tile(range(0, initial_size), num_nodes)

    if method == "tile":
        repetitions = math.ceil(rows/len(loco_types))
        types = np.tile(loco_types, repetitions).tolist()[0:rows]
    elif method == "shares_twoway":
        if((len(loco_types) != 2) | (len(shares) != 2)):
            raise ValueError(
                f"""2-way prescribed locopool requested but number of locomotive types is not 2.""")

        idx_1 = np.argmin(shares)
        idx_2 = 1 - idx_1
        share_type_one = shares[idx_1]
        label_type_one = loco_types[idx_1]
        label_type_two = loco_types[idx_2]

        num_type_one = round(initial_size * share_type_one)
        if 0 == num_type_one:
            types = pd.Series([label_type_two] * initial_size)
        elif initial_size == num_type_one:
            types = pd.Series([label_type_one] * initial_size)
        else:
            # Arrange repeated sequences of type 1 + {type_two_per_type_one, type_two_per_type_one+1} type 2
            # so as to match the required total counts of each.
            type_two_per_type_one = (
                initial_size - num_type_one) / num_type_one
            # Number of type 1 + {type_two_per_bel+1} type 2 sequences needed
            num_extra_type_two = round(
                num_type_one * (type_two_per_type_one % 1.0))
            series_fewer_type_two = pd.Series(
                [label_type_one] + [label_type_two] * math.floor(type_two_per_type_one))
            series_more_type_two = pd.Series(
                [label_type_one] + [label_type_two] * math.ceil(type_two_per_type_one))
            types = np.concatenate((
                np.tile(series_more_type_two, num_extra_type_two),
                np.tile(series_fewer_type_two, num_type_one-num_extra_type_two)),
                axis=None)
        types = np.tile(types, num_nodes).tolist()
    else:
        raise ValueError(
            f"""Locopool build method '{method}' invalid or not implemented.""")

    loco_pool = pl.DataFrame(
        {'Locomotive_ID': pl.Series(engine_numbers, dtype=pl.UInt32),
         'Type': pl.Series(types, dtype=pl.Categorical),
         'Node': pl.Series(sorted_nodes, dtype=pl.Categorical),
         'Ready_Time_Min': pl.Series(np.zeros(rows), dtype=pl.Float64),
         'Ready_Time_Est': pl.Series(np.zeros(rows), dtype=pl.Float64),
         'Status': pl.Series(np.tile("Ready", rows), dtype=pl.Categorical),
         'Charger_J_Per_Hr': pl.Series(np.zeros(rows), dtype=pl.Float64), 
         'Queue_Size': pl.Series(np.zeros(rows), dtype=pl.UInt32)}
    )

    loco_info_pl = pl.from_pandas(config.loco_info.drop(labels='Rust_Loco',axis=1),
        schema_overrides={'Type': pl.Categorical}
    )

    loco_pool = loco_pool.join(loco_info_pl, on="Type")
    return loco_pool


def build_refuel_facility_consist(
    node_list,
    loco_pool,
    capacity_per_incoming_corridor=1,
) -> pl.DataFrame:
    """
    Build the default set of refueling facilities.
    Arguments:
    ----------
    node_list: List of origin or destination demand nodes
    loco_pool: Locomotive pool
    capacity_per_incoming_corridor: Queue size per corridor arriving at each node.
    Outputs:
    ----------
    refuel_facilities: Polars dataframe of facility county by node and type of fuel
    """

    bel_share = len(loco_pool.filter(pl.col('Type') == pl.lit('BEL')))/len(loco_pool)
    capacity_per_node = (len(node_list) - 1) * capacity_per_incoming_corridor
    types = ["BEL", "Diesel_Large"]
    speeds = [DEFAULT_BEL_CHARGE_RATE, DEFAULT_REFUEL_RATE] # joules per hour
    ports = [math.ceil(capacity_per_node * bel_share), math.ceil(capacity_per_node * (1 - bel_share))]
    locations = pd.DataFrame(data={
        'Node': np.tile(node_list, len(types))})
    locations = locations.sort_values(by=['Node']).reset_index(drop=True)
    refuel_facilities = pl.DataFrame({
        'Node': pl.Series(locations['Node'], dtype=pl.Categorical).cast(pl.Categorical),
        'Type': pl.Series(np.tile(types, len(node_list)), dtype=pl.Categorical).cast(pl.Categorical),
        'Charger_J_Per_Hr': pl.Series(np.tile(speeds, len(node_list)), dtype=pl.Float64),
        'Queue_Size': pl.Series(np.tile(ports, len(node_list)), dtype=pl.UInt32)})

    return refuel_facilities

def update_loco_info(loco_info: pd.DataFrame) -> pd.DataFrame:
    if all(item in loco_info.columns for item in [
        'HP','Loco_Mass_Tons','SOC_J','SOC_Min_J','SOC_Max_J','Capacity_J'
        ]
    ): return loco_info
    
    get_hp = lambda loco: loco.pwr_rated_kilowatts * 1e3 / alt.utils.W_PER_HP
    get_mass_ton = lambda loco: loco.mass_kg / alt.utils.KG_PER_TON
    get_starting_soc = lambda loco: DEFAULT_DIESEL_TANK_CAPACITY if not loco.res else loco.res.state.soc * loco.res.energy_capacity_joules
    get_min_soc = lambda loco: 0 if not loco.res else loco.res.min_soc * loco.res.energy_capacity_joules
    get_max_soc = lambda loco: DEFAULT_DIESEL_TANK_CAPACITY if not loco.res else loco.res.max_soc * loco.res.energy_capacity_joules
    get_capacity = lambda loco: DEFAULT_DIESEL_TANK_CAPACITY if not loco.res else loco.res.energy_capacity_joules
    loco_info.loc[:,'HP'] = loco_info.loc[:,'Rust_Loco'].apply(get_hp) 
    loco_info.loc[:,'Loco_Mass_Tons'] = loco_info.loc[:,'Rust_Loco'].apply(get_mass_ton) 
    loco_info.loc[:,'SOC_J'] = loco_info.loc[:,'Rust_Loco'].apply(get_starting_soc) 
    loco_info.loc[:,'SOC_Min_J'] = loco_info.loc[:,'Rust_Loco'].apply(get_min_soc) 
    loco_info.loc[:,'SOC_Max_J'] = loco_info.loc[:,'Rust_Loco'].apply(get_max_soc) 
    loco_info.loc[:,'Capacity_J'] = loco_info.loc[:,'Rust_Loco'].apply(get_capacity) 
    return loco_info


def dispatch(
    dispatch_time: int,
    ton: int,
    origin: str,
    destination: str,
    loco_pool: pl.DataFrame,
    train_type: str,
    config: TrainPlannerConfig,
    hp_per_ton: float = None,
) -> pl.Series:
    """
    Update the locomotive pool by identifying the desired locomotive to dispatch and assign to the
    new location (destination) with corresponding updated ready time
    Arguments:
    ----------
    dispatch_time: time that a train is due
    ton: required tonnage in the train
    origin: origin node name of the train
    origin: destination node name of the train
    loco_pool: locomotive pool dataframe containing all locomotives in the network
    config: Object storing train planner configuration paramaters
    train_type: Type of train (should match with a value on config.hp_required_per_ton)
    Outputs:
    ----------
    selected: Indices of selected locomotives
    """
    if hp_per_ton is None:
        od_string = f'{origin}_{destination}'
        if (od_string in config.hp_required_per_ton) and (train_type in config.hp_required_per_ton[od_string]):
            hp_per_ton = config.hp_required_per_ton[od_string][train_type]
        elif ("Default" in config.hp_required_per_ton) and (train_type in config.hp_required_per_ton["Default"]):
            hp_per_ton = config.hp_required_per_ton["Default"][train_type]
        else: hp_per_ton = 0

    hp_required = ton * hp_per_ton

    # Candidate locomotives at the right place that are ready

    candidates = loco_pool.select((pl.col("Node") == origin) &
                                (pl.col("Status") == "Ready")).to_series()
    if not candidates.any():
        message = f"""No available locomotives at node {origin} at hour {dispatch_time}. Count of
            locomotives refueling or waiting to refuel at {origin} are:"""
        waiting_counts = loco_pool.filter((pl.col("Status").is_in(["Servicing","Refueling","Queued"])) & (pl.col("Node") == origin)
                                        ).groupby(['Type']).count()
        for row in waiting_counts.iter_rows(named = True):
            message = message + f"""
            {row['Type']}: {row['count']}"""

        raise ValueError(message)

    # Running list of downselected candidates
    selected = candidates
    # First available diesel (in order of loco_pool) will be moved from candidates to selected
    # TODO gracefully handle cases when there is no diesel locomotive to be dispatched
    # (ex: hold the train until enough diesels are present)
    diesel_candidates = loco_pool.select(pl.lit(candidates) &
                                       pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel")).to_series()
    if not diesel_candidates.any():
        refueling_diesel_count = loco_pool.filter(
            (pl.col("Node") == origin) &
            (pl.col("Status").is_in(["Servicing","Refueling","Queued"])) &
            (pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel"))
        ).select(pl.count())[0, 0]
        message = f"""No available diesel locomotives at node {origin} at hour {dispatch_time}, so
                the one-diesel-per-consist rule cannot be satisfied. {refueling_diesel_count} diesel locomotives at
                {origin} are servicing, refueling, or queueing."""
        if refueling_diesel_count > 0:
            diesel_queue_size = loco_pool.filter(
                (pl.col("Node") == origin) &
                (pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel"))
            ).select(pl.col("Queue_Size").min())[0, 0]
            message += f""" (queue capacity {diesel_queue_size})."""
        else:
            message += "."
        raise ValueError(message)

    diesel_to_require = diesel_candidates.eq(True).cumsum().eq(1).arg_max()
    diesel_to_require_hp = loco_pool.filter(
        pl.col("Type") == "Diesel_Large").select(pl.first("HP"))
    # Need to mask this so it's not double-counted on next step
    candidates[diesel_to_require] = False
    # Get running sum, including first diesel, of hp of the candidates (in order of loco_pool)
    enough_hp = loco_pool.select((
        (
            (pl.col("HP") - (pl.col("Loco_Mass_Tons") * pl.lit(hp_per_ton))) * pl.lit(candidates)
        ).cumsum() + pl.lit(diesel_to_require_hp)) >= hp_required).to_series()
    if not enough_hp.any():
        available_hp = loco_pool.select(
            (
                (pl.col("HP") - (pl.col("Loco_Mass_Tons") * pl.lit(hp_per_ton))) * pl.lit(candidates)
            ).cumsum().max())[0, 0]
        message = f"""Outbound horsepower needed ({hp_required}) at {origin} at hour {dispatch_time}
            is more than the available horsepower ({available_hp}).
            Count of locomotives servicing, refueling, or queueing at {origin} are:"""
        # Hold the train until enough diesels are present (future development)
        waiting_counts = loco_pool.filter(
            (pl.col("Node") == origin) & (pl.col("Status").is_in(["Servicing","Queued","Refueling"]))
        ).select("Type").groupby(['Type']).count()
        for idx, row in waiting_counts.iter_rows(named = True):
            message = message + f"""
            {row['Type']}: {row['counts']}"""
        # Hold the train until enough locomotives are present (future development)
        raise ValueError(message)

    last_row_to_use = enough_hp.eq(True).cumsum().eq(1).arg_max()
    # Set false all the locomotives that would add unnecessary hp
    selected[np.arange(last_row_to_use+1, len(selected))] = False
    # Add first diesel (which could come after last_row_to_use) to selection list
    selected[diesel_to_require] = True
    return selected

def run_train_planner(
    rail_vehicle_map: Dict[str, alt.RailVehicle],
    location_map: Dict[str, List[alt.Location]],
    network: List[alt.Link],
    loco_pool: pl.DataFrame,
    refuel_facilities: pl.DataFrame,
    simulation_days: int,
    config: TrainPlannerConfig = TrainPlannerConfig(),
    # change file name here to test different cases
    demand_file_path=alt.resources_root() / "Default Demand.csv",
) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame, List[alt.SpeedLimitTrainSim], List[alt.EstTimeNet]]:
    """
    Run the train planner
    Arguments:
    ----------
    rail_vehicle_map:
    location_map:
    network:
    loco_pool:
    refuel_facilities:
    simulation_days:
    config: Object storing train planner configuration paramaters
    demand_file_path: 
    Outputs:
    ----------
    """
    config.loco_info = update_loco_info(config.loco_info)
    df_annual_demand, node_list = demand_loader(demand_file_path)
    
    if refuel_facilities is None: 
        refuel_facilities = build_refuel_facility_consist(node_list, loco_pool)
    
    df_additional_demand = additional_demand(df_annual_demand, config)
    df_origin_manifest_demand = origin_manifest_demand(df_annual_demand, node_list, config)
    df_origin_manifest_demand, df_balance_storage = train_balancer(df_origin_manifest_demand)
    df_demand_pair = demand_pair_generator(
        df_annual_demand, df_additional_demand, df_balance_storage, node_list)
    df_demand_train = demand_train_generator(df_demand_pair, config.target_train_length)
    df_timesteps = timestep_calculator(config, df_demand_train, simulation_days * 24 * 60)
    df_timesteps.loc[:, 'Hour'] = df_timesteps.loc[:,'Timestep']/60
    train_consist_plan = pd.DataFrame(columns=[
        'Train ID',
        'Train Type',
        'Locomotive ID',
        'Locomotive Type',
        "Origin ID",
        'Destination ID',
        'Number of Loaded Railcars',
        'Number of Empty Railcars',
        'Planned Departure Time(hr)',
        'Planned Arrival Time(hr)'
    ])
    df_event_tracker = pd.DataFrame(columns=[
        'Event Type',
        'Time(hr)',
        'Locomotive ID'
    ])

    train_id_counter = 1
    speed_limit_train_sims = []
    est_time_nets = []

    done = False
    # start at first departure time
    current_time = np.min(df_timesteps['Hour'])
    while not done:
        # Remove locomotives that are done refueling from the refuel queue
        refueling_finished = loco_pool.select(
            (pl.col("Status") == "Refueling") & (pl.col("Ready_Time_Est") <= current_time)).to_series()
        refueling_finished_count = pl.sum(refueling_finished)
        if(refueling_finished_count > 0):
            refueling_times = loco_pool.filter(refueling_finished).select((pl.col('SOC_Max_J')-pl.col('SOC_J'))/pl.col('Charger_J_Per_Hr')).to_series()
            loco_pool = loco_pool.with_columns(
                pl.when(refueling_finished)
                .then(pl.col("SOC_Max_J"))
                .otherwise(pl.col('SOC_J'))
                .alias("SOC_J"),
                pl.when(pl.lit(refueling_finished) & (pl.col("Ready_Time_Min") <= current_time))
                    .then(pl.lit("Ready"))
                    .when(pl.lit(refueling_finished) & (pl.col("Ready_Time_Min") > current_time))
                    .then(pl.lit("Servicing"))
                    .otherwise(pl.col('Status'))
                    .alias("Status"),
                pl.when(pl.lit(refueling_finished) & (pl.col("Ready_Time_Min") <= current_time))
                    .then(pl.lit(current_time))
                    .when(pl.lit(refueling_finished) & (pl.col("Ready_Time_Min") > current_time))
                    .then(pl.col('Ready_Time_Min'))
                    .otherwise(pl.col('Ready_Time_Est'))
                    .alias("Ready_Time_Est")
            )
            # Record the refueling event
            new_rows = pd.DataFrame(list(zip(
                np.concatenate([
                    np.tile('Refueling_Start', refueling_finished_count),
                    np.tile('Refueling_End', refueling_finished_count)]),
                np.concatenate([current_time - refueling_times,
                    np.tile(current_time, refueling_finished_count)]),
                np.tile(loco_pool.filter(refueling_finished).select('Locomotive_ID').to_series(), 2))),
                columns=df_event_tracker.columns)
            df_event_tracker = pd.concat(
                (df_event_tracker, new_rows)).reset_index(drop=True)
            
        # Update locomotives that are done servicing 
        # (this only applies to those that finished refueling before minimum service time elapsed)
        servicing_finished = loco_pool.select(
            (pl.col("Status") == "Servicing") & (pl.col("Ready_Time_Min") <= current_time)).to_series()
        servicing_finished_count = pl.sum(servicing_finished)
        if(servicing_finished_count > 0):
            loco_pool = loco_pool.with_columns(
                pl.when(servicing_finished)
                    .then(pl.lit("Ready"))
                    .otherwise(pl.col('Status'))
                    .alias("Status")
            )

        # Add locomotives that are done traveling to the service queue
        arrived = loco_pool.select((pl.col("Status") == "Dispatched") &
                                 (pl.col("Ready_Time_Est") <= current_time)).to_series()
        arrived_count = pl.sum(arrived)
        if(arrived_count > 0):
            loco_pool.drop_in_place('Charger_J_Per_Hr')
            loco_pool.drop_in_place('Queue_Size')
            loco_pool = loco_pool.join(refuel_facilities, on=["Node", "Type"], how="left")
            loco_pool = loco_pool.with_columns(
                pl.when(arrived)
                .then(pl.lit("Queued"))
                .otherwise(pl.col('Status'))
                .alias("Status"),
                pl.when(arrived)
                .then(current_time + pl.col("Min_Servicing_Time[hr]"))
                .otherwise(pl.col('Ready_Time_Min'))
                .alias("Ready_Time_Min")
            )
            loco_pool = loco_pool.sort("Ready_Time_Est", "Locomotive_ID", descending = False, nulls_last = True)

        # If any refuelings finished or any trains arrived, update the refueling queue
        if((arrived_count > 0) | (refueling_finished_count > 0)):

            queued = loco_pool.select(pl.col("Status") == 'Queued').to_series()
            place_in_queue = loco_pool.select(
                ((pl.col('Status') == 'Refueling').sum().over(['Node', 'Type']) +
                (pl.col('Status') == 'Queued').cumsum().over(['Node', 'Type']))               
                .alias('queue_position')
                ).to_series()
            loco_pool = loco_pool.with_columns(
                pl.when(pl.lit(queued) & (
                pl.lit(place_in_queue) <= pl.col('Queue_Size')))
                .then('Refueling')
                .otherwise(pl.col('Status'))
                .alias("Status"),
                pl.when(pl.lit(queued) & (
                pl.lit(place_in_queue) <= pl.col('Queue_Size')))
                .then(current_time + 
                        (pl.col('SOC_Max_J')-pl.col('SOC_J'))/pl.col('Charger_J_Per_Hr')
                )
                .otherwise(pl.col('Ready_Time_Est'))
                .alias("Ready_Time_Est"))

        # Dispatch new train consists
        current_dispatches = np.where(df_timesteps['Hour'] == current_time)[0]
        if(len(current_dispatches) > 0):
            df_current_dispatches = df_timesteps.loc[current_dispatches, :]
            for idx, row_actual_interval in df_current_dispatches.iterrows():
                origin = row_actual_interval['Origin']
                destination = row_actual_interval['Destination']
                train_type = row_actual_interval.loc['Train Type']

                df_demand_pair_row = df_demand_pair[(df_demand_pair['Origin'] == origin) &
                                                    (df_demand_pair['Destination'] == destination)].iloc[0]
                df_demand_train_row = df_demand_train[(df_demand_train['Origin'] == origin) &
                                                      (df_demand_train['Destination'] == destination)].iloc[0]
                tonnage = df_demand_pair_row.loc[train_type] * config.ton_per_car[train_type]
                railcars_loaded = np.floor(df_demand_pair_row.loc[train_type]/df_demand_train_row.loc[train_type])
                railcars_empty = 0

                if train_type == "Intermodal":
                    railcars_empty = np.floor(
                        df_demand_pair_row.loc['Intermodal_Empty']/df_demand_train_row.loc['Intermodal'])
                    tonnage += df_demand_pair_row.loc['Intermodal_Empty'] * config.ton_per_car["Intermodal_Empty"]
                elif train_type == "Unit_Empty":
                    railcars_empty = railcars_loaded
                    railcars_loaded = 0
                elif train_type == "Manifest":
                    railcars_empty = np.floor(
                        df_demand_pair_row.loc['Manifest_Empty']/df_demand_train_row.loc['Manifest_Empty'])
                    tonnage += df_demand_pair_row.loc['Manifest_Empty']*config.ton_per_car["Manifest_Empty"]

                if tonnage > 0:
                    selected = dispatch(
                        current_time,
                        math.ceil(
                            tonnage / df_demand_train_row.loc[train_type]),
                        origin,
                        destination,
                        loco_pool,
                        train_type,
                        config
                    )

                    train_summary = alt.TrainSummary(
                        train_type,
                        int(railcars_empty),
                        int(railcars_loaded),
                        None,
                        None,
                        None)
                    
                    dispatched = loco_pool.filter(selected)
                    dispatch_order =  (dispatched.select(
                        pl.col('Locomotive_ID')
                        .rank().alias('rank').cast(pl.UInt32)
                        ).with_row_count().sort('row_nr'))
                    dispatched = dispatched.sort('Locomotive_ID')
                    loco_types = dispatched.select('Type').to_series()
                    loco_start_soc = dispatched.select(pl.col('SOC_J') / pl.col('Capacity_J')).to_series()
                    locos = [config.loco_info[config.loco_info['Type']==loco_type]['Rust_Loco'].to_list()[0].clone() for loco_type in loco_types]
                    [alt.set_param_from_path(locos[i], "res.state.soc", loco_start_soc[i]) for i in range(len(locos)) if loco_types[i] == 'BEL']

                    loco_con = alt.Consist(
                        loco_vec=locos,
                        save_interval=None,
                    )

                    init_train_state = alt.InitTrainState(
                        time_seconds=current_time * 3600,
                    )

                    tsb = alt.TrainSimBuilder(
                        train_id=str(train_id_counter),
                        origin_id=origin,
                        destination_id=destination,
                        train_summary=train_summary,
                        loco_con=loco_con,
                        init_train_state=init_train_state,
                    )

                    slts = tsb.make_speed_limit_train_sim(
                        rail_vehicle_map, location_map, None, None, None)
                    (est_time_net, loco_con_out) = alt.make_est_times(slts, network)
                    travel_time = (
                        est_time_net.get_running_time_hours()
                        * config.dispatch_scaling_dict["time_mult_factor"] 
                        + config.dispatch_scaling_dict["hours_add"]
                    )
                    locos = loco_con_out.loco_vec.tolist()
                    energy_use_locos = [loco.res.state.energy_out_chemical_joules if loco.res else loco.fc.state.energy_fuel_joules if loco.fc else 0 for loco in locos]
                    energy_use_j = np.zeros(len(loco_pool))
                    energy_use_j[selected] = [energy_use_locos[i-1] for i in dispatch_order.select('rank').to_series().to_list()] 
                    energy_use_j *= config.dispatch_scaling_dict["energy_mult_factor"]
                    energy_use_j = pl.Series(energy_use_j)
                    speed_limit_train_sims.append(slts)
                    est_time_nets.append(est_time_net)

                    loco_pool = loco_pool.with_columns(
                        pl.when(selected)
                        .then(pl.lit("Dispatched"))
                        .otherwise(pl.col('Status'))
                        .alias("Status"),
                        pl.when(selected)
                        .then(pl.lit(destination))
                        .otherwise(pl.col('Node'))
                        .alias("Node"),
                        pl.when(selected)
                        .then(pl.lit(current_time + travel_time))
                        .otherwise(pl.col('Ready_Time_Min'))
                        .alias("Ready_Time_Min"),
                        pl.when(selected)
                        .then(pl.lit(current_time + travel_time))
                        .otherwise(pl.col('Ready_Time_Est'))
                        .alias("Ready_Time_Est"),
                        pl.when(selected)
                        .then(
                            pl.max(
                                pl.col('SOC_Min_J'),
                                pl.min(
                                    pl.col('SOC_J') - pl.lit(energy_use_j), 
                                    pl.col('SOC_Max_J')
                                    )
                            )
                        )
                        .otherwise(pl.col('SOC_J'))
                        .alias("SOC_J")
                    )

                    # Populate the output dataframe with the dispatched trains
                    new_row_count = len(selected)
                    new_rows = pd.DataFrame(list(zip(
                        repeat(train_id_counter, new_row_count),
                        repeat(train_type, new_row_count),
                        loco_pool.filter(selected).select(
                            'Locomotive_ID').to_series(),
                        loco_pool.filter(selected).select('Type').to_series(),
                        repeat(origin, new_row_count),
                        repeat(destination, new_row_count),
                        repeat(railcars_loaded, new_row_count),
                        repeat(railcars_empty, new_row_count),
                        repeat(current_time),
                        repeat(current_time + travel_time, new_row_count))),
                        columns=train_consist_plan.columns)

                    train_consist_plan = pd.concat(
                        (
                            train_consist_plan,
                            new_rows)
                    ).reset_index(drop=True)
                    train_id_counter += 1

            df_timesteps.drop(index=current_dispatches, inplace=True)
            df_timesteps.reset_index(drop=True, inplace=True)

        active_loco_ready_times = loco_pool.filter(
            pl.col("Status").is_in(['Refueling','Servicing','Dispatched'])).select("Ready_Time_Est").to_series()
        if((len(active_loco_ready_times) == 0) & (len(df_timesteps) == 0)):
            done = True
        else:
            current_time = pl.min(pl.concat(
                [pl.from_pandas(df_timesteps['Hour']),
                active_loco_ready_times]))
            
    df_event_tracker.sort_values(
        by=['Locomotive ID', 'Time(hr)', 'Event Type'], inplace=True)
    service_starts = df_event_tracker[df_event_tracker['Event Type']
                                      == 'Refueling_Start'].reset_index(drop=True)
    service_ends = df_event_tracker[df_event_tracker['Event Type']
                                    == 'Refueling_End'].reset_index(drop=True)
    
    train_consist_plan = pl.from_pandas(train_consist_plan,
                                             schema_overrides={'Train Type': str,
                                                               'Locomotive Type': str,
                                                               'Origin ID': str,
                                                               'Destination ID': str,
                                                               'Train ID': pl.UInt32,
                                                               'Locomotive ID': pl.UInt32}
                                             ).sort(["Locomotive ID", "Train ID"], descending=False)
    loco_pool = loco_pool.with_columns(
        pl.col("Type").cast(str).alias("Type"),
        pl.col("Node").cast(str).alias("Node"),
    )
    refuel_facilities = refuel_facilities.with_columns(
        pl.col("Type").cast(str).alias("Type"),
        pl.col("Node").cast(str).alias("Node"),
    )
    train_consist_plan = train_consist_plan.with_columns(
        pl.Series(service_starts['Time(hr)']).alias('Planned Refuel Start Time(hr)'),
        pl.Series(service_ends['Time(hr)']).alias('Planned Refuel End Time(hr)')
    )
    
    return train_consist_plan, loco_pool, refuel_facilities, speed_limit_train_sims, est_time_nets


if __name__ == "__main__":
    rail_vehicle_map = alt.import_rail_vehicles(
        str(alt.resources_root() / "rolling_stock/rail_vehicles.csv")
    )
    location_map = alt.import_locations(
        str(alt.resources_root() / "networks/default_locations.csv")
    )
    network = alt.import_network(
        str(alt.resources_root() / "networks/Taconite.yaml")
    )
    output = run_train_planner(
        rail_vehicle_map=rail_vehicle_map, location_map=location_map, network=network)
    # print(output)
