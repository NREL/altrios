from pathlib import Path
from typing import Union
import numpy as np
from scipy.stats import rankdata
import pandas as pd
import math
from typing import Tuple, List, Optional, Dict
from itertools import repeat
import altrios as alt
import polars as pl
pl.enable_string_cache(True)

TRAIN_TYPE_HP_PER_T_REQUIREMENT = {
    "Unit": 1+2.0,
    "Manifest": 1.5+2.0,
    "Intermodal": 2+2.0,
    "Unit_Empty": 1+2.0,
}

TIME_STEP = 0.1


def input_loader(
    user_input_file: Union[Path, str],
    dict_train_type_hp_t=TRAIN_TYPE_HP_PER_T_REQUIREMENT,
    time_step=TIME_STEP
) -> Tuple[pd.DataFrame, pd.Series, int]:
    """
    Load the user input csv file into a dataframe for later processing
    Arguments:
    ----------
    user_input_file: path to the input csv file that user import to the module
    Example Input:
        Origin	Destination	Train_Type	Number_of_Cars	Number_of_Containers
        Barstow	Stockton	Unit	    2394	        0
        Barstow	Stockton	Manifest	2588	        0
        Barstow	Stockton	Intermodal	2221	        2221

    Outputs:
    ----------
    df_annual_demand: dataframe with all pair information including:
    origin, destination, train type, number of cars
    node_list: List of origin or destination demand nodes
    """
    df_annual_demand = pd.read_csv(user_input_file)
    df_annual_demand["HP_T"] = [dict_train_type_hp_t[tt]
                                for tt in df_annual_demand["Train_Type"]]
    node_list = pd.concat(
        (df_annual_demand["Origin"],
         df_annual_demand["Destination"])
    ).unique()

    return df_annual_demand, node_list


MANIFEST_EMPTY_RETURN_RATIO = 0.6


def additional_demand(
    df_annual_demand: pd.DataFrame,
    manifest_empty_return_ratio: float = MANIFEST_EMPTY_RETURN_RATIO
) -> pd.DataFrame:
    """
    Create a dataframe for additional demand needed for empty cars of the return trains
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    manifest_empty_return_ratio: Desired railcar reuse ratio defined by user
    (E_ij+E_ji)/(L_ij+L_ji)
    Outputs:
    ----------
    df_additional_demand: The demand generated by the need
    of returning the empty cars to their original nodes
    """
    df_additional_demand = pd.DataFrame(
        np.zeros(shape=np.shape(df_annual_demand)),
        columns=df_annual_demand.columns)

    df_additional_demand["Origin"] = df_annual_demand["Destination"]
    df_additional_demand["Destination"] = df_annual_demand["Origin"]
    df_additional_demand["Train_Type"] = df_annual_demand["Train_Type"]

    for i in range(len(df_annual_demand)):
        df_additional_demand.loc[i,
                                 "Number_of_Containers"] = df_annual_demand.loc[i, "Number_of_Containers"]
        if df_additional_demand.loc[i, "Train_Type"] == "Manifest":
            df_additional_demand.loc[i, "Number_of_Cars"] = np.floor(
                df_annual_demand.loc[i, "Number_of_Cars"] * manifest_empty_return_ratio)
        else:
            df_additional_demand.loc[i,
                                     "Number_of_Cars"] = df_annual_demand.loc[i, "Number_of_Cars"]

    return df_additional_demand


def origin_manifest_demand(
    df_annual_demand: pd.DataFrame,
    df_additional_demand: pd.DataFrame,
    node_list: List[str],
    manifest_empty_return_ratio: float = MANIFEST_EMPTY_RETURN_RATIO
) -> pd.DataFrame:
    """
    Create a dataframe for summarized view of all origins' manifest demand
    in number of cars and received cars, both with loaded and empty counts
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    df_additional_demand: The demand generated by the need
    of returning the empty cars to their original nodes
    node_list: A list containing all the names of nodes in the system
    manifest_empty_return_ratio: The manifest return ratio to calculate the empty manifest car demand

    Outputs:
    ----------
    df_origin_manifest_demand: The dataframe that summarized all the manifest demand
    originated from each node by number of loaded and empty cars
    with additional columns for checking the unbalance quantity and serve as check columns
    for the manifest empty car rebalancing function
    """
    df_origin_manifest_demand = pd.DataFrame(
        np.zeros(shape=(len(node_list), 8)),
        columns=[
            "Origin",
            "Manifest",
            "Manifest_Empty",
            "Manifest_Dispatched",
            "Manifest_Received",
            "Manifest_Dispatched_Check",
            "Manifest_Received_Check",
            "Manifest_Empty_Updated",
        ]
    )

    df_origin_manifest_demand["Origin"] = node_list

    for i in range(len(df_annual_demand)):
        for j in range(len(node_list)):
            if (df_annual_demand.loc[i, "Origin"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"]
            if (df_annual_demand.loc[i, "Destination"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Empty"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"] * manifest_empty_return_ratio
            if (df_annual_demand.loc[i, "Destination"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Received"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"]
            if (df_annual_demand.loc[i, "Origin"] == node_list[j]) and (
                    df_annual_demand.loc[i, "Train_Type"] == "Manifest"):
                df_origin_manifest_demand.loc[j, "Manifest_Received"] \
                    += df_annual_demand.loc[i, "Number_of_Cars"] * manifest_empty_return_ratio

    df_origin_manifest_demand["Manifest_Dispatched"] = (
        df_origin_manifest_demand["Manifest"] +
        df_origin_manifest_demand["Manifest_Empty"]
    )

    for i in range(len(df_origin_manifest_demand)):
        df_origin_manifest_demand.loc[i, "Manifest_Received_Check"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Received"]
        df_origin_manifest_demand.loc[i, "Manifest_Dispatched_Check"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Dispatched"]
        df_origin_manifest_demand.loc[i, "Manifest_Empty_Updated"] \
            = df_origin_manifest_demand.loc[i, "Manifest_Empty"]

    return df_origin_manifest_demand


def train_balancer(
    df_origin_manifest_demand: pd.DataFrame
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Update the manifest demand, especially the empty car demand to maintain equilibrium of number of
    cars dispatched and received at each node for manifest
    Arguments:
    ----------
    df_origin_manifest_demand: The dataframe that summarized all the manifest demand
    originated from each node by number of loaded and empty cars
    with additional columns for checking the unbalance quantity and serve as check columns
    Outputs:
    ----------
    df_origin_manifest_demand: Updated df_origin_manifest_demand with additional
    manifest empty car demand added to each node
    df_balance_storage: Documented additional manifest demand pairs and corresponding quantity for
    rebalancing process
    """
    # Creating a copy of the origin manifest demand,
    # which is a dataframe of the number of manifest cars dispatched and received for each node,
    # with two checking columns for modifications
    # df_origin_manifest_demand_copy = df_origin_manifest_demand.copy()
    # Calculate the number of iterations needed
    df_balance_storage = np.zeros(shape=(0, 3))
    df_balance_storage = pd.DataFrame(df_balance_storage)
    df_balance_storage = df_balance_storage.rename(
        columns={0: "Origin", 1: "Destination", 2: "Extra_Empty", })

    step = 0
    max_iter = len(df_origin_manifest_demand) * \
        (len(df_origin_manifest_demand)-1) / 2
    while (~np.isclose(df_origin_manifest_demand["Manifest_Received_Check"],
                       df_origin_manifest_demand["Manifest_Dispatched_Check"])).any() and (step <= max_iter):
        for row_def in range(len(df_origin_manifest_demand)):
            # Find the first node that is in deficit of cars because of the empty return
            if df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] \
                    < df_origin_manifest_demand.loc[row_def, "Manifest_Dispatched_Check"]:
                for row_sur in range(len(df_origin_manifest_demand)):
                    # Find the first node that is in surplus of cars
                    if df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] \
                            > df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"]:
                        df_balance_storage.loc[len(df_balance_storage.index)] = [df_origin_manifest_demand.loc[row_sur, "Origin"],
                                                                                 df_origin_manifest_demand.loc[
                                                                                     row_def, "Origin"],
                                                                                 (df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] -
                                                                                  df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"])
                                                                                 ]
                        df_origin_manifest_demand.loc[row_sur, "Manifest_Empty_Updated"] \
                            = df_origin_manifest_demand.loc[row_sur, "Manifest_Empty_Updated"] + \
                            df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] - \
                            df_origin_manifest_demand.loc[row_sur,
                                                          "Manifest_Dispatched_Check"]
                        df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] \
                            = df_origin_manifest_demand.loc[row_def, "Manifest_Received_Check"] + \
                            df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"] - \
                            df_origin_manifest_demand.loc[row_sur,
                                                          "Manifest_Dispatched_Check"]
                        df_origin_manifest_demand.loc[row_sur, "Manifest_Dispatched_Check"] \
                            = df_origin_manifest_demand.loc[row_sur, "Manifest_Received_Check"]

                        step += 1
                        break
    if (~np.isclose(df_origin_manifest_demand["Manifest_Received_Check"],
                    df_origin_manifest_demand["Manifest_Dispatched_Check"])).any():
        raise Exception("While loop didn't converge")
    return df_origin_manifest_demand, df_balance_storage


def demand_pair_generator(
    df_annual_demand: pd.DataFrame,
    df_additional_demand: pd.DataFrame,
    df_balance_storage: pd.DataFrame,
    node_list: List[str]
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the final demand
    for each demand pair for each train type in number of cars
    Arguments:
    ----------
    df_annual_demand: The user_input file loaded by previous functions
    that contains laoded demand for each demand pair.
    df_additional_demand: The demand generated by the need
    of returning the empty cars to their original nodes
    df_balance_storage: Documented additional manifest demand pairs and corresponding quantity for
    rebalancing process
    node_list: A list containing all the names of nodes in the system
    Outputs:
    ----------
    df_demand_pair: Tabulated demand for each demand pair for each train type
    """
    # Dispatch logic curretly set to be dispatching in 100 cars when applicable
    df_demand_pair = pd.DataFrame(
        np.zeros(shape=(len(node_list)*(len(node_list)-1), 9)),
        columns=[
            'Origin',
            'Destination',
            'Intermodal',
            'Intermodal_Empty',
            'Unit',
            'Unit_Empty',
            'Manifest',
            'Manifest_Empty',
            'Total'
        ]
    )

    for i in range(len(node_list)):
        iter = 0
        for j in range(len(node_list)):
            if i != j:
                df_demand_pair.loc[
                    i*(len(node_list)-1)+iter, "Origin"
                ] = node_list[i]
                df_demand_pair.loc[
                    i*(len(node_list)-1)+iter, "Destination"
                ] = node_list[j]
                iter += 1
    type = {"Intermodal": 1, "Unit": 2, "Manifest": 3}
    nodes = {row["Origin"] + row["Destination"]             : i for (i, row) in df_demand_pair.iterrows()}

    for (i, row) in df_annual_demand.iterrows():
        df_demand_pair.iloc[
            nodes[row["Origin"] + row["Destination"]], 2 *
            type[row["Train_Type"]]
        ] = row["Number_of_Cars"]

    for (i, row) in df_additional_demand.iterrows():
        df_demand_pair.iloc[
            nodes[row["Origin"] + row["Destination"]], 2 *
            type[row["Train_Type"]] + 1
        ] += row["Number_of_Cars"]

    for (i, row) in df_balance_storage.iterrows():
        df_demand_pair.loc[
            nodes[
                row["Origin"] + row["Destination"]
            ], "Manifest_Empty"
        ] += row["Extra_Empty"]

    df_demand_pair["Total"] = df_demand_pair.iloc[:, 2:-1].sum()

    return df_demand_pair


def demand_train_generator(
    df_demand_pair: pd.DataFrame,
    min_length: int = 60,
    desired_length: int = 100
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the final demand
    for each demand pair for each train type in number of trains
    Arguments:
    ----------
    df_demand_pair: Tabulated demand for each demand pair for each train type in number of cars
    min_length: the minimum length in number of cars to form a train
    desired_length: the standard train length in number of cars
    Outputs:
    ----------
    df_demand_train: Tabulated demand for each demand pair for each train type in number of trains
    """
    df_demand_train = df_demand_pair.copy()

    for i in range(len(df_demand_train)):
        temp = df_demand_pair.loc[i, "Manifest"] + \
            df_demand_pair.loc[i, "Manifest_Empty"]
        if temp - np.floor(temp/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Manifest"] = np.floor(
                temp/desired_length) + 1
        else:
            df_demand_train.loc[i, "Manifest"] = np.floor(temp/desired_length)
        df_demand_train.loc[i,
                            "Manifest_Empty"] = df_demand_train.loc[i, "Manifest"]

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Intermodal"] != 0:
            if df_demand_pair.loc[i, "Intermodal"] - np.floor(df_demand_pair.loc[i, "Intermodal"]/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal"]/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal"]/desired_length)
        if df_demand_pair.loc[i, "Intermodal_Empty"] != 0:
            if df_demand_pair.loc[i, "Intermodal_Empty"] - np.floor(df_demand_pair.iloc[i, 3]/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal_Empty"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal_Empty"]/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal_Empty"] = np.floor(
                    df_demand_pair.loc[i, "Intermodal_Empty"]/desired_length)
        if df_demand_pair.loc[i, "Intermodal"] != 0 and df_demand_pair.loc[i, "Intermodal_Empty"] != 0:
            temp = df_demand_pair.loc[i, "Intermodal"] + \
                df_demand_pair.loc[i, "Intermodal_Empty"]
            if temp - np.floor(temp/desired_length) * desired_length > min_length:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    temp/desired_length) + 1
            else:
                df_demand_train.loc[i, "Intermodal"] = np.floor(
                    temp/desired_length)
            df_demand_train.loc[i, "Intermodal_Empty"] = 0.0

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Unit"] - np.floor(df_demand_pair.loc[i, "Unit"]/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Unit"] = np.floor(
                df_demand_pair.loc[i, "Unit"]/desired_length) + 1
        else:
            df_demand_train.loc[i, "Unit"] = np.floor(
                df_demand_pair.loc[i, "Unit"]/desired_length)

    for i in range(len(df_demand_train)):
        if df_demand_pair.loc[i, "Unit_Empty"] - np.floor(df_demand_pair.loc[i, "Unit_Empty"]/desired_length) * desired_length > min_length:
            df_demand_train.loc[i, "Unit_Empty"] = np.floor(
                df_demand_pair.loc[i, "Unit_Empty"]/desired_length) + 1
        else:
            df_demand_train.loc[i, "Unit_Empty"] = np.floor(
                df_demand_pair.loc[i, "Unit_Empty"]/desired_length)
    for i in range(len(df_demand_train)):
        df_demand_train.loc[i, "Total"] = 0
        for j in range(5):
            df_demand_train.loc[i, "Total"] += df_demand_train.iloc[i, j+2]

    return df_demand_train


def timestep_calculator(
    df_demand_train: pd.DataFrame,
    time_steps: int = 21*24*10
) -> pd.DataFrame:
    """
    Generate a tabulated demand pair to indicate the expected dispatching interval
    and actual dispatching timesteps after rounding
    Arguments:
    ----------
    df_demand_train: Tabulated demand for each demand pair for each train type in number of trains
    time_steps: Number of iterations, a product of time interval (number of iterations per hour)
    and time period (in hours)
    Outputs:
    ----------
    df_timesteps: Tabulated dispatching time for each demand pair for each train type
    in hours
    """
    df_rounded_intervals = pd.melt(df_demand_train, id_vars=[
                                   'Origin', 'Destination'], value_vars=train_types)
    df_rounded_intervals.loc[:, 'interval'] = round(
        time_steps / df_rounded_intervals.loc[:, 'value'])
    df_rounded_intervals = df_rounded_intervals[(
        df_rounded_intervals['value'] > 0) & (df_rounded_intervals['interval'] > 0)]
    column_names = ['Timestep', 'Origin', 'Destination', 'Train Type']
    df_timesteps = pd.DataFrame(columns=column_names)
    for j, row in df_rounded_intervals.iterrows():
        timesteps = np.arange(1, row.loc['value']+1)*row.loc['interval']
        new_row_count = len(timesteps)
        new_rows = pd.DataFrame(list(zip(
            timesteps,
            repeat(row.loc['Origin'], new_row_count),
            repeat(row.loc['Destination'], new_row_count),
            repeat(row.loc['variable'], new_row_count))),
            columns=column_names)

        df_timesteps = pd.concat(
            (
                df_timesteps,
                new_rows)
        ).reset_index(drop=True)

    df_timesteps.sort_values(
        by=['Timestep', 'Origin', 'Destination', 'Train Type'],
        inplace=True)
    df_timesteps.reset_index(drop=True, inplace=True)

    return df_timesteps


def get_default_loco_info() -> Dict[str, any]:
    loco_info = {
        # #"Hydrogen_Cell":{
        #     "Capacity_Cars": 30,
        #     "Servicing_Time[hr]": 3,
        #     "Rust_Loco_File": str(alt.resources_root())
        # },
        "Diesel_Large": {
            "Capacity_Cars": 20,
            "Servicing_Time[hr]": 20,
            "Rust_Loco": alt.Locomotive.default(),
        },
        # #"Diesel_Medium":{
        #     "Capacity_Cars":30,
        #     "Servicing_Time[hr]":20
        # },
        # "Diesel_Small":{
        #     "Capacity_Cars":20,
        #     "Servicing_Time[hr]":20
        # },
        "BEL": {
            "Capacity_Cars": 20,
            "Servicing_Time[hr]": 20,  # subject to change
            "Rust_Loco": alt.Locomotive.default_battery_electic_loco(),
        }
    }

    return loco_info


train_types = (
    "Intermodal",
    "Intermodal_Empty",
    "Unit",
    "Unit_Empty",
    "Manifest",
    "Manifest_Empty"
)

CAR_INFO = {
    "Unit": {
        "Ton_per_Car": 80,
    },
    "Unit_Empty": {
        "Ton_per_Car": 30,
    },
    "Intermodal": {
        "Ton_per_Car": 70,
    },
    "Intermodal_Empty": {
        "Ton_per_Car": 15,
    },
    "Manifest": {
        "Ton_per_Car": 100,
    },
    "Manifest_Empty": {
        "Ton_per_Car": 30,
    },
}


def carinfo_loader():
    """
    Load the provided car information by users
    Arguments:
    ----------

    Outputs:
    ----------
    car_info: dictionary containing all cars' information that are within the system
    """
    # Actual carinfo builder
    pass


def build_locopool(
    demand_file: str = alt.resources_root() / "Default Demand.csv",
    loco_info: Dict[str, any] = get_default_loco_info(),
    method: str = "tile",
    shares: List[float] = [],
    cars_per_locomotive: int = 40
) -> pl.DataFrame:
    """
    Generate default locomotive pool
    Arguments:
    ----------
    demand_file: Path to a file with origin-destination demand
    loco_info: Dictionary with keys representing unique locomotive types
    method: Method to determine each locomotive's type ("tile" or "shares_twoway" currently implemented)
    shares: List of shares for each locomotive type in loco_info (implemented for two-way shares only)
    cars_per_locomotive: Heuristic scaling factor used to size number of locomotives needed based on demand.
    Outputs:
    ----------
    df_pool: Locomotive pool containing all locomotives' information that are within the system
    """
    df_annual_demand, node_list = input_loader(demand_file)
    num_nodes = len(node_list)
    num_ods = len(df_annual_demand)
    cars_per_od = np.mean(df_annual_demand['Number_of_Cars'])
    num_destinations_per_node = num_ods / num_nodes
    initial_size = math.ceil((cars_per_od / cars_per_locomotive) *
                             num_destinations_per_node)  # number of locomotives per node

    rows = initial_size * num_nodes  # number of locomotives in total
    sorted_nodes = np.sort(np.tile(node_list, initial_size)).tolist()
    engine_numbers = rankdata(sorted_nodes, method="dense") * 1000 + \
        np.tile(range(0, initial_size), num_nodes)

    if method == "tile":
        repetitions = math.ceil(rows/len(loco_info))
        types = np.tile(list(loco_info.keys()), repetitions).tolist()[0:rows]
    elif method == "shares_twoway":
        if((len(loco_info) != 2) | (len(shares) != 2)):
            raise ValueError(
                f"""2-way prescribed locopool requested but number of locomotive types is not 2.""")

        idx_1 = np.argmin(shares)
        idx_2 = 1 - idx_1
        share_type_one = shares[idx_1]
        label_type_one = list(loco_info.keys())[idx_1]
        label_type_two = list(loco_info.keys())[idx_2]

        num_type_one = round(initial_size * share_type_one)
        if 0 == num_type_one:
            types = pd.Series([label_type_two] * initial_size)
        elif initial_size == num_type_one:
            types = pd.Series([label_type_one] * initial_size)
        else:
            # Arrange repeated sequences of type 1 + {type_two_per_type_one, type_two_per_type_one+1} type 2
            # so as to match the required total counts of each.
            type_two_per_type_one = (
                initial_size - num_type_one) / num_type_one
            # Number of type 1 + {type_two_per_bel+1} type 2 sequences needed
            num_extra_type_two = round(
                num_type_one * (type_two_per_type_one % 1.0))
            series_fewer_type_two = pd.Series(
                [label_type_one] + [label_type_two] * math.floor(type_two_per_type_one))
            series_more_type_two = pd.Series(
                [label_type_one] + [label_type_two] * math.ceil(type_two_per_type_one))
            types = np.concatenate((
                np.tile(series_more_type_two, num_extra_type_two),
                np.tile(series_fewer_type_two, num_type_one-num_extra_type_two)),
                axis=None)
        types = np.tile(types, len(node_list)).tolist()
    else:
        raise ValueError(
            f"""Locopool build method '{method}' invalid or not implemented.""")

    df_pool = pl.DataFrame(
        {'Engine_Number': pl.Series(engine_numbers, dtype=pl.Int32),
         'Type': pl.Series(types, dtype=pl.Categorical),
         'Node': pl.Series(sorted_nodes, dtype=pl.Categorical),
         'Ready_Time': pl.Series(np.zeros(rows), dtype=pl.Float64),
         'Status': pl.Series(np.tile("Ready", rows), dtype=pl.Categorical),
         'Queue_Size': pl.Series(np.zeros(rows), dtype=pl.Int32)}
    )

    loco_info_pl = pl.from_pandas(pd.DataFrame(
        update_loco_info(loco_info)
    ).transpose().reset_index().drop(labels='Rust_Loco', axis=1).rename(columns={"index": "Type"}),
        schema_overrides={
            'Type': pl.Categorical,
    }
    )

    df_pool = df_pool.join(loco_info_pl, on="Type")
    return df_pool


def default_refuel_facility_consist(
    node_list,
    capacity_per_incoming_corridor=6
):
    """
    Build the default set of refueling facilities.
    Arguments:
    ----------
    node_list: List of origin or destination demand nodes
    capacity_per_incoming_corridor: Queue size per corridor arriving at each node.
    Outputs:
    ----------
    refuel_facilities: Polars dataframe of facility county by node and type of fuel
    """

    capacity_per_node = (len(node_list) - 1) * capacity_per_incoming_corridor
    types = ["BEL", "Diesel_Large"]
    values = [capacity_per_node, capacity_per_node]
    locations = pd.DataFrame(data={
        'Node': np.tile(node_list, len(types))})
    locations = locations.sort_values(by=['Node']).reset_index(drop=True)
    refuel_facilities = pl.DataFrame({
        'Node': pl.Series(locations['Node'], dtype=pl.Categorical).cast(pl.Categorical),
        'Type': pl.Series(np.tile(types, len(node_list)), dtype=pl.Categorical).cast(pl.Categorical),
        'Queue_Size': pl.Series(np.tile(values, len(node_list)), dtype=pl.UInt32)})

    return refuel_facilities


DEFAULT_MEET_PASS_DICT = {
    "time_mult_factor": 1.4,
    "hours_add": 2
}


def prescribed_locopool(
    bel_share: float
) -> pd.DataFrame:
    """
    Generates a locomotive pool matching the share of locomotives specified by a prescribed rollout.
    As of now, this only supports diesel and battery electric locomotives, but it should be made more generic.
    Arguments:
    ----------
    bel_share: The share of BEL units (expressed as a 0-1 range) to include
    Outputs:
    ----------
    df_pool: Locomotive pool containing all locomotives' information that are within the system
    """
    _, node_list = input_loader(
        alt.resources_root() / "Default Demand.csv")
    initial_size = 40 * len(node_list)
    loco_info = update_loco_info(get_default_loco_info())
    df_pool = pd.DataFrame(
        np.zeros(shape=(initial_size*len(node_list), len(df_pool_column_names))), columns=df_pool_column_names)

    num_bel = round(initial_size * bel_share)
    if 0 == num_bel:
        types = pd.Series(["Diesel_Large"] * initial_size)
    elif initial_size == num_bel:
        types = pd.Series(["BEL"] * initial_size)
    else:
        # Arrange repeated sequences of BEL + {non_bel_per_bel, non_bel_per_bel+1} Diesel
        # so as to match the required total counts of each.
        non_bel_per_bel = (initial_size - num_bel) / num_bel
        # Number of BEL + {non_bel_per_bel+1} sequences needed
        num_extra_non_bel = round(num_bel * (non_bel_per_bel % 1.0))
        series_fewer_non_bel = pd.Series(
            ["BEL"] + ["Diesel_Large"] * math.floor(non_bel_per_bel))
        series_more_non_bel = pd.Series(
            ["BEL"] + ["Diesel_Large"] * math.ceil(non_bel_per_bel))
        types = np.concatenate((
            np.tile(series_more_non_bel, num_extra_non_bel),
            np.tile(series_fewer_non_bel, num_bel-num_extra_non_bel)),
            axis=None)

    types = np.tile(types, len(node_list))
    df_pool["Type"] = types

    for i in range(len(node_list)):
        for j in range(initial_size):
            index = i*initial_size+j
            df_pool.loc[index, "Node"] = node_list[i]
            df_pool.loc[index, "Engine_Number"] = j + 1000 * (i + 1)

            df_pool.loc[index, "Capacity_Cars"] = loco_info[df_pool.loc[index,
                                                                        "Type"]]["Capacity_Cars"]
            df_pool.loc[index, "HP"] = loco_info[df_pool.loc[index,
                                                             "Type"]]["HP"]
            # loco_info[df_pool.loc[index,"Type"]]["Servicing_Time[hr]"]
            df_pool.loc[index, "Ready_Time"] = 0
            df_pool.loc[index, "Status"] = "Ready"
            df_pool.loc[index, "Queue_Size"] = 0

    return df_pool


def update_loco_info(loco_info: Dict[str, any]) -> Dict[str, any]:
    for key, val in loco_info.items():
        loco_info[key]['HP'] = val['Rust_Loco'].pwr_rated_kilowatts * \
            1e3 / alt.utils.W_PER_HP
    return loco_info


def dispatch(
    dispatch_time: int,
    ton: int,
    origin: str,
    df_pool: pl.DataFrame,
    train_type: str = "Manifest",
    hp_per_ton: float = None,
) -> pl.Series:
    """
    Update the locomotive pool by identifying the desired locomotive to dispatch and assign to the
    new location (destination) with corresponding updated ready time
    Arguments:
    ----------
    dispatch_time: time that a train is due
    ton: required tonnage in the train
    origin: origin node name of the train
    df_pool: locomotive pool dataframe containing all locomotives in the network
    Outputs:
    ----------
    selected: Indices of selected locomotives
    """

    if hp_per_ton is None:
        hp_per_ton = TRAIN_TYPE_HP_PER_T_REQUIREMENT[train_type]

    hp_required = ton * hp_per_ton

    # Candidate locomotives at the right place that are ready

    candidates = df_pool.select((pl.col("Node") == origin) &
                                (pl.col("Status") == "Ready")).to_series()
    if not candidates.any():
        message = f"""No available locomotives at node {origin} at hour {dispatch_time}. Count of
            locomotives refueling or waiting to refuel at {origin} are:"""
        waiting_counts = df_pool[(df_pool['Node'] == origin) & (
            df_pool['Status'] == 'Servicing')].value_counts(['Type'])
        waiting_counts = waiting_counts.reset_index()
        for idx, row in waiting_counts.iterrows():
            message = message + f"""
            {row['Type']}: {row['count']}"""

        raise ValueError(message)

    # Running list of downselected candidates
    selected = candidates
    # First available diesel (in order of df_pool) will be moved from candidates to selected
    # TODO gracefully handle cases when there is no diesel locomotive to be dispatched
    # (ex: hold the train until enough diesels are present)
    diesel_candidates = df_pool.select(pl.lit(candidates) &
                                       pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel")).to_series()
    if not diesel_candidates.any():
        refueling_diesel_count = df_pool.filter(
            (pl.col("Node") == origin) &
            (pl.col("Status") == 'Servicing') &
            (pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel"))
        ).select(pl.count())[0, 0]
        message = f"""No available diesel locomotives at node {origin} at hour {dispatch_time}, so
                the one-diesel-per-consist rule cannot be satisfied. {refueling_diesel_count} diesel locomotives at
                {origin} are refueling or waiting to refuel"""
        if refueling_diesel_count > 0:
            diesel_queue_size = df_pool.filter(
                (pl.col("Node") == origin) &
                (pl.col("Type").cast(pl.Utf8).str.contains("(?i)diesel"))
            ).select(pl.col("Queue_Size").min())[0, 0]
            message += f""" (queue capacity {diesel_queue_size})."""
        else:
            message += "."
        raise ValueError(message)

    diesel_to_require = diesel_candidates.eq(True).cumsum().eq(1).arg_max()
    diesel_to_require_hp = df_pool.filter(
        pl.col("Type") == "Diesel_Large").select(pl.first("HP"))
    # Need to mask this so it's not double-counted on next step
    candidates[diesel_to_require] = False
    # Get running sum, including first diesel, of hp of the candidates (in order of df_pool)
    enough_hp = df_pool.select((pl.col("HP") * pl.lit(candidates)
                                ).cumsum() + pl.lit(diesel_to_require_hp) >= hp_required).to_series()
    if not enough_hp.any():
        available_hp = df_pool.select(
            (pl.col("HP") * pl.lit(candidates)).cumsum().max())[0, 0]
        message = f"""Outbound horsepower needed ({hp_required}) at {origin} at hour {dispatch_time}
            is more than the available horsepower ({available_hp}).
            Count of locomotives refueling or waiting to refuel at {origin} are:"""
        # Hold the train until enough diesels are present (future development)
        waiting_counts = df_pool.filter(
            (pl.col("Node") == origin) & (pl.col("Status") == "Servicing")
        ).select("Type").to_series().value_counts()
        waiting_counts = waiting_counts.to_pandas()
        for idx, row in waiting_counts.iterrows():
            message = message + f"""
            {row['Type']}: {row['counts']}"""
        # Hold the train until enough locomotives are present (future development)
        raise ValueError(message)

    last_row_to_use = enough_hp.eq(True).cumsum().eq(1).arg_max()
    # Set false all the locomotives that would add unnecessary hp
    selected[np.arange(last_row_to_use+1, len(selected))] = False
    # Add first diesel (which could come after last_row_to_use) to selection list
    selected[diesel_to_require] = True
    return selected


def run_train_planner(
    rail_vehicle_map,
    location_map,
    network,
    manifest_empty_return_ratio=MANIFEST_EMPTY_RETURN_RATIO,
    df_pool=build_locopool(),
    loco_info=get_default_loco_info(),
    simulation_days=21,
    meet_pass_dict=DEFAULT_MEET_PASS_DICT,
    # change file name here to test different cases
    demand_file_path=alt.resources_root() / "Default Demand.csv",
) -> Tuple[pd.DataFrame, List[alt.SpeedLimitTrainSim], List[alt.EstTimeNet]]:
    time_step_divisor = 60
    df_annual_demand, node_list = input_loader(demand_file_path)
    test_span_hr = simulation_days * 24
    simulation_steps = test_span_hr*time_step_divisor
    df_additional_demand = additional_demand(
        df_annual_demand, manifest_empty_return_ratio)
    df_origin_manifest_demand = origin_manifest_demand(
        df_annual_demand, df_additional_demand, node_list, MANIFEST_EMPTY_RETURN_RATIO)
    df_origin_manifest_demand, df_balance_storage = train_balancer(
        df_origin_manifest_demand)
    df_demand_pair = demand_pair_generator(
        df_annual_demand, df_additional_demand, df_balance_storage, node_list)
    df_demand_train = demand_train_generator(df_demand_pair, 60)
    df_timesteps = timestep_calculator(df_demand_train, simulation_steps)
    df_timesteps.loc[:, 'Hour'] = df_timesteps.loc[:,
                                                   'Timestep']/time_step_divisor
    df_train_consist_output = pd.DataFrame(columns=[
        'Train ID',
        'Train Type',
        'Locomotive ID',
        'Locomotive Type',
        "Origin ID",
        'Destination ID',
        'Number of Loaded Railcars',
        'Number of Empty Railcars',
        'Origin Departure Time(hr)',
        'Destination Arrival Time(hr)',
        'Servicing Start Time(hr)',
        'Servicing End Time(hr)'
    ])
    df_event_tracker = pd.DataFrame(columns=[
        'Event Type',
        'Time(hr)',
        'Locomotive ID'
    ])

    REFUEL_CAP = default_refuel_facility_consist(node_list)

    train_id_counter = 1
    speed_limit_train_sims = []
    est_time_nets = []

    done = False
    # start at first departure time
    current_time = np.min(df_timesteps['Hour'])
    while not done:
        # Remove locomotives that are done refueling from the refuel queue
        servicing_finished = df_pool.select((pl.col("Status") == "Servicing") &
                                            (pl.col("Ready_Time") <= current_time)).to_series()
        finished_count = pl.sum(servicing_finished)
        if(finished_count > 0):
            df_pool = df_pool.with_columns(
                pl.when(servicing_finished)
                .then(pl.lit("Ready"))
                .otherwise(pl.col('Status'))
                .alias("Status"),
                pl.when(servicing_finished)
                .then(pl.lit(current_time))
                .otherwise(pl.col('Ready_Time'))
                .alias("Ready_Time")
            )
            # Record the refueling event
            new_rows = pd.DataFrame(list(zip(
                np.concatenate([
                    np.tile('Servicing_Start', finished_count),
                    np.tile('Servicing_End', finished_count)]),
                np.concatenate([
                    current_time -
                    df_pool.filter(servicing_finished).select(
                        'Servicing_Time[hr]').to_series(),
                    np.tile(current_time, finished_count)]),
                np.tile(df_pool.filter(servicing_finished).select('Engine_Number').to_series(), 2))),
                columns=df_event_tracker.columns)
            df_event_tracker = pd.concat(
                (df_event_tracker, new_rows)).reset_index(drop=True)

        # Add locomotives that are done traveling to the service queue
        arrived = df_pool.select((pl.col("Status") == "Dispatched") &
                                 (pl.col("Ready_Time") <= current_time)).to_series()
        arrived_count = pl.sum(arrived)
        if(arrived_count > 0):
            df_pool.drop_in_place('Queue_Size')
            df_pool = df_pool.join(REFUEL_CAP, on=["Node", "Type"], how="left")
            df_pool = df_pool.with_columns(
                pl.when(arrived)
                .then(pl.lit("Servicing"))
                .otherwise(pl.col('Status'))
                .alias("Status"),
                pl.when(arrived)
                .then(pl.lit(np.Inf))
                .otherwise(pl.col('Ready_Time'))
                .alias("Ready_Time")
            )

        # If any refuelings finished or any trains arrived, update the refueling queue
        if((arrived_count > 0) | (finished_count > 0)):
            servicing = df_pool.select(
                pl.col("Status") == "Servicing").to_series()
            place_in_queue = df_pool.select((pl.col('Status') == 'Servicing').cumsum().over([
                                            'Node', 'Type']).alias('cumsum')).to_series()
            refueling = df_pool.select(pl.lit(servicing) & (
                place_in_queue <= pl.col('Queue_Size'))).to_series()
            df_pool = df_pool.with_columns(
                pl.when(refueling)
                .then(pl.min
                      (pl.col('Ready_Time'),
                       current_time+pl.col('Servicing_Time[hr]'))
                      )
                .otherwise(pl.col('Ready_Time'))
                .alias("Ready_Time"))

        # Dispatch new train consists
        current_dispatches = np.where(df_timesteps['Hour'] == current_time)[0]
        if(len(current_dispatches) > 0):
            df_current_dispatches = df_timesteps.loc[current_dispatches, :]
            for idx, row_actual_interval in df_current_dispatches.iterrows():
                origin = row_actual_interval['Origin']
                destination = row_actual_interval['Destination']
                tonnage = 0
                df_demand_pair_row = df_demand_pair[(df_demand_pair['Origin'] == origin) &
                                                    (df_demand_pair['Destination'] == destination)].iloc[0]
                df_demand_train_row = df_demand_train[(df_demand_train['Origin'] == origin) &
                                                      (df_demand_train['Destination'] == destination)].iloc[0]
                train_type = row_actual_interval.loc['Train Type']
                if train_type == "Intermodal":
                    tonnage = (
                        df_demand_pair_row.loc['Intermodal']*CAR_INFO["Intermodal"]["Ton_per_Car"] +
                        df_demand_pair_row.loc['Intermodal_Empty'] *
                        CAR_INFO["Intermodal_Empty"]["Ton_per_Car"]
                    )
                    railcars_loaded = np.floor(
                        df_demand_pair_row.loc['Intermodal']/df_demand_train_row.loc['Intermodal'])
                    railcars_empty = np.floor(
                        df_demand_pair_row.loc['Intermodal_Empty']/df_demand_train_row.loc['Intermodal'])

                if train_type == "Unit":
                    tonnage = (
                        df_demand_pair_row.loc[train_type] * CAR_INFO[train_type]["Ton_per_Car"])
                    railcars_loaded = np.floor(
                        df_demand_pair_row.loc[train_type]/df_demand_train_row.loc[train_type])
                    railcars_empty = 0

                if train_type == "Unit_Empty":
                    tonnage = (df_demand_pair_row.loc[train_type] * CAR_INFO[train_type]["Ton_per_Car"]
                               )
                    railcars_loaded = 0
                    railcars_empty = np.floor(
                        df_demand_pair_row.loc[train_type]/df_demand_train_row.loc[train_type])

                if train_type == "Manifest":
                    tonnage = (df_demand_pair_row.loc['Manifest']*CAR_INFO["Manifest"]["Ton_per_Car"]
                               + df_demand_pair_row.loc['Manifest_Empty']*CAR_INFO["Manifest_Empty"]["Ton_per_Car"])

                    railcars_loaded = np.floor(
                        df_demand_pair_row.loc['Manifest']/df_demand_train_row.loc['Manifest'])
                    railcars_empty = np.floor(
                        df_demand_pair_row.loc['Manifest_Empty']/df_demand_train_row.loc['Manifest_Empty'])

                if tonnage > 0:
                    selected = dispatch(
                        current_time,
                        math.ceil(
                            tonnage / df_demand_train_row.loc[train_type]),
                        origin,
                        df_pool,
                        train_type
                    )

                    train_summary = alt.TrainSummary(
                        train_type,
                        int(railcars_empty),
                        int(railcars_loaded),
                        None,
                        None,
                        None)

                    loco_con = alt.Consist(
                        loco_vec=[
                            loco_info[loco_type]['Rust_Loco'].clone() for loco_type in df_pool.filter(selected).select('Type').to_series()
                        ],
                        save_interval=None,
                    )

                    init_train_state = alt.InitTrainState(
                        time_seconds=current_time * 3600,
                    )

                    tsb = alt.TrainSimBuilder(
                        train_id=str(train_id_counter),
                        origin_id=origin,
                        destination_id=destination,
                        train_summary=train_summary,
                        loco_con=loco_con,
                        init_train_state=init_train_state,
                    )

                    slts = tsb.make_speed_limit_train_sim(
                        rail_vehicle_map, location_map, None, None, None)
                    (est_time_net, loco_con) = alt.make_est_times(slts, network)
                    travel_time = (
                        est_time_net.get_running_time_hours()
                        * meet_pass_dict["time_mult_factor"] + meet_pass_dict["hours_add"]
                    )

                    speed_limit_train_sims.append(slts)
                    est_time_nets.append(est_time_net)

                    df_pool = df_pool.with_columns(
                        pl.when(selected)
                        .then(pl.lit("Dispatched"))
                        .otherwise(pl.col('Status'))
                        .alias("Status"),
                        pl.when(selected)
                        .then(pl.lit(destination))
                        .otherwise(pl.col('Node'))
                        .alias("Node"),
                        pl.when(selected)
                        .then(pl.lit(current_time + travel_time))
                        .otherwise(pl.col('Ready_Time'))
                        .alias("Ready_Time")
                    )

                    # Populate the output dataframe with the dispatched trains
                    new_row_count = len(selected)
                    new_rows = pd.DataFrame(list(zip(
                        repeat(train_id_counter, new_row_count),
                        repeat(train_type, new_row_count),
                        df_pool.filter(selected).select(
                            'Engine_Number').to_series(),
                        df_pool.filter(selected).select('Type').to_series(),
                        repeat(origin, new_row_count),
                        repeat(destination, new_row_count),
                        repeat(railcars_loaded, new_row_count),
                        repeat(railcars_empty, new_row_count),
                        repeat(current_time),
                        repeat(current_time + travel_time, new_row_count),
                        repeat(np.nan, new_row_count),
                        repeat(np.nan, new_row_count))),
                        columns=df_train_consist_output.columns)

                    df_train_consist_output = pd.concat(
                        (
                            df_train_consist_output,
                            new_rows)
                    ).reset_index(drop=True)
                    train_id_counter += 1

            df_timesteps.drop(index=current_dispatches, inplace=True)
            df_timesteps.reset_index(drop=True, inplace=True)

        active_loco_ready_times = df_pool.filter(
            pl.col("Status") != "Ready").select("Ready_Time").to_series()
        if((len(active_loco_ready_times) == 0) & (len(df_timesteps) == 0)):
            done = True
        else:
            current_time = min(
                pd.concat([active_loco_ready_times.to_pandas(), df_timesteps['Hour']]))

    df_train_consist_output = df_train_consist_output.reset_index(drop=True)

    df_train_consist_output = df_train_consist_output.sort_values(
        by=['Locomotive ID', 'Train ID']).reset_index(drop=True)

    df_event_tracker.sort_values(
        by=['Locomotive ID', 'Time(hr)', 'Event Type'], inplace=True)
    service_starts = df_event_tracker[df_event_tracker['Event Type']
                                      == 'Servicing_Start'].reset_index(drop=True)
    service_ends = df_event_tracker[df_event_tracker['Event Type']
                                    == 'Servicing_End'].reset_index(drop=True)

    df_train_consist_output.loc[:,
                                'Servicing Start Time(hr)'] = service_starts['Time(hr)']
    df_train_consist_output.loc[:,
                                'Servicing End Time(hr)'] = service_ends['Time(hr)']

    return df_train_consist_output, speed_limit_train_sims, est_time_nets


if __name__ == "__main__":
    rail_vehicle_map = alt.import_rail_vehicles(
        str(alt.resources_root() / "rolling_stock/rail_vehicles.csv")
    )
    location_map = alt.import_locations(
        str(alt.resources_root() / "networks/default_locations.csv")
    )
    network = alt.import_network(
        str(alt.resources_root() / "networks/Taconite.yaml")
    )
    output = run_train_planner(
        rail_vehicle_map=rail_vehicle_map, location_map=location_map, network=network)
    # print(output)
